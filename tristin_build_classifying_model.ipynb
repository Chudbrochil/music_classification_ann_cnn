{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 'jupyter notebook' from Conda Terminal before beginning to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7336789590827771961\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4952306483\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3156192566879497811\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "Tensorflow:  1.11.0\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# Testing to make sure TensorFlow GPU is working\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, shuffle data, normalize data, split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 124, 174, 3)\n",
      "(9000, 10)\n",
      "Validation x train set:(1800, 124, 174, 3)\n",
      "X train set:(7200, 124, 174, 3)\n",
      "Validation y train set:(1800, 10)\n",
      "Y train set:(7200, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load(\"X_mel_train_3.dat\")\n",
    "y_train = np.load(\"y_mel_train_3.dat\")\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=16)\n",
    "# reshape so in form for CNN-Keras\n",
    "#X_train = X_train.reshape(X_train.shape[0], 174, 124, 1)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "# split data into validation set\n",
    "training_set_size = int(X_train.shape[0] * .80)\n",
    "X_train_validation = X_train[training_set_size:, :,:,:]\n",
    "y_train_validation = y_train[training_set_size:, :]\n",
    "y_train = y_train[:training_set_size,:]\n",
    "X_train = X_train[:training_set_size, :, :, :]\n",
    "print(\"Validation x train set:\" + str(X_train_validation.shape))\n",
    "print(\"X train set:\" + str(X_train.shape))\n",
    "print(\"Validation y train set:\" + str(y_train_validation.shape))\n",
    "print(\"Y train set:\" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 like network from Andrew Ng's course on Coursera\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "    # this applies 32 convolution filters of size 3x3 each.\n",
    "    model.add(BatchNormalization(input_shape=X_train.shape[1:]))\n",
    "    \n",
    "    model.add(Conv2D(64, (7,7), activation = 'relu', strides=(1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(128, (7, 7), activation = 'relu', strides=(1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())    \n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(256, (7, 7), activation = 'relu', strides=(1,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "    # model.add(Conv2D(512, (7, 7), activation = 'relu', strides=(1,1)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "    # model.add(Conv2D(256, (7, 7), activation = 'relu', strides=(1,1)))\n",
    "    # # # model.add(BatchNormalization())\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # # # model.add(Dropout(0.5))\n",
    "\n",
    "    # # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 2.3727 - acc: 0.2464 - val_loss: 1.8749 - val_acc: 0.3317\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.9330 - acc: 0.3249 - val_loss: 1.6849 - val_acc: 0.3972\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.7975 - acc: 0.3731 - val_loss: 1.6865 - val_acc: 0.3878\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.7010 - acc: 0.4001 - val_loss: 1.6132 - val_acc: 0.4083\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 1.6302 - acc: 0.4279 - val_loss: 1.4376 - val_acc: 0.4833\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 48s 216ms/step - loss: 1.6113 - acc: 0.4286 - val_loss: 1.4825 - val_acc: 0.4683\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 1.5431 - acc: 0.4606 - val_loss: 1.4499 - val_acc: 0.4772\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.5244 - acc: 0.4667 - val_loss: 1.3980 - val_acc: 0.5078\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.5056 - acc: 0.4672 - val_loss: 1.4063 - val_acc: 0.5144\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.4698 - acc: 0.4900 - val_loss: 1.3259 - val_acc: 0.5239\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.4134 - acc: 0.5040 - val_loss: 1.3033 - val_acc: 0.5417\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.4193 - acc: 0.5046 - val_loss: 1.2516 - val_acc: 0.5733\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.3999 - acc: 0.5186 - val_loss: 1.2571 - val_acc: 0.5544\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.3732 - acc: 0.5247 - val_loss: 1.1854 - val_acc: 0.5917\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 1.3759 - acc: 0.5300 - val_loss: 1.4009 - val_acc: 0.4850\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.3404 - acc: 0.5371 - val_loss: 1.2938 - val_acc: 0.5422\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.3511 - acc: 0.5368 - val_loss: 1.1881 - val_acc: 0.5944\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 48s 216ms/step - loss: 1.3151 - acc: 0.5460 - val_loss: 1.1519 - val_acc: 0.5972\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.2978 - acc: 0.5469 - val_loss: 1.2151 - val_acc: 0.5783\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.2963 - acc: 0.5567 - val_loss: 1.2360 - val_acc: 0.5600\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.2772 - acc: 0.5633 - val_loss: 1.1756 - val_acc: 0.5978\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 1.2591 - acc: 0.5604 - val_loss: 1.2401 - val_acc: 0.5861\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.2583 - acc: 0.5732 - val_loss: 1.1842 - val_acc: 0.5878\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.2285 - acc: 0.5821 - val_loss: 1.2447 - val_acc: 0.5517\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.2207 - acc: 0.5861 - val_loss: 1.0420 - val_acc: 0.6478\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.2007 - acc: 0.5954 - val_loss: 1.3188 - val_acc: 0.5378\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.2180 - acc: 0.5813 - val_loss: 1.0767 - val_acc: 0.6183\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.1966 - acc: 0.5949 - val_loss: 1.0921 - val_acc: 0.6194\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.1928 - acc: 0.6010 - val_loss: 1.0174 - val_acc: 0.6478\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.1784 - acc: 0.5988 - val_loss: 1.0619 - val_acc: 0.6344\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.1674 - acc: 0.6019 - val_loss: 0.9853 - val_acc: 0.6561\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.1510 - acc: 0.6126 - val_loss: 1.0843 - val_acc: 0.6283\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.1405 - acc: 0.6156 - val_loss: 1.0637 - val_acc: 0.6211\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.1499 - acc: 0.6100 - val_loss: 1.0774 - val_acc: 0.6244\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.1318 - acc: 0.6161 - val_loss: 1.1120 - val_acc: 0.6089\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.1287 - acc: 0.6186 - val_loss: 1.1500 - val_acc: 0.5906\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.0993 - acc: 0.6269 - val_loss: 0.9646 - val_acc: 0.6656\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.1095 - acc: 0.6289 - val_loss: 0.9581 - val_acc: 0.6622\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.0838 - acc: 0.6332 - val_loss: 1.0825 - val_acc: 0.6317\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.0840 - acc: 0.6368 - val_loss: 0.9818 - val_acc: 0.6478\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.0698 - acc: 0.6440 - val_loss: 1.1045 - val_acc: 0.6317\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.0588 - acc: 0.6432 - val_loss: 0.9582 - val_acc: 0.6717\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.0669 - acc: 0.6415 - val_loss: 0.9294 - val_acc: 0.6756\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.0598 - acc: 0.6428 - val_loss: 1.1128 - val_acc: 0.5989\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.0365 - acc: 0.6522 - val_loss: 0.9988 - val_acc: 0.6639\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 1.0419 - acc: 0.6460 - val_loss: 1.0472 - val_acc: 0.6344\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.0340 - acc: 0.6522 - val_loss: 0.8629 - val_acc: 0.6994\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.0369 - acc: 0.6472 - val_loss: 0.8679 - val_acc: 0.6961\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.0131 - acc: 0.6607 - val_loss: 0.9377 - val_acc: 0.6806\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 1.0067 - acc: 0.6636 - val_loss: 0.8585 - val_acc: 0.6961\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 1.0043 - acc: 0.6674 - val_loss: 1.0263 - val_acc: 0.6478\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9953 - acc: 0.6697 - val_loss: 0.9611 - val_acc: 0.6522\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9862 - acc: 0.6699 - val_loss: 0.9135 - val_acc: 0.6806\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9775 - acc: 0.6714 - val_loss: 1.0237 - val_acc: 0.6506\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9779 - acc: 0.6754 - val_loss: 1.0827 - val_acc: 0.6394\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.9655 - acc: 0.6810 - val_loss: 1.1588 - val_acc: 0.6072\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9656 - acc: 0.6783 - val_loss: 0.9681 - val_acc: 0.6467\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.9482 - acc: 0.6851 - val_loss: 0.9754 - val_acc: 0.6672\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.9435 - acc: 0.6853 - val_loss: 0.8784 - val_acc: 0.6950\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9490 - acc: 0.6793 - val_loss: 0.9920 - val_acc: 0.6450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "225/225 [==============================] - 48s 216ms/step - loss: 0.9171 - acc: 0.6932 - val_loss: 0.8857 - val_acc: 0.6833\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 48s 214ms/step - loss: 0.9300 - acc: 0.6889 - val_loss: 0.8622 - val_acc: 0.7028\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.9329 - acc: 0.6882 - val_loss: 0.8588 - val_acc: 0.6922\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9168 - acc: 0.6894 - val_loss: 0.8548 - val_acc: 0.7017\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 48s 214ms/step - loss: 0.9259 - acc: 0.6857 - val_loss: 0.8707 - val_acc: 0.7089\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 48s 216ms/step - loss: 0.9198 - acc: 0.6925 - val_loss: 0.8279 - val_acc: 0.7217\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9027 - acc: 0.6964 - val_loss: 0.8076 - val_acc: 0.7178\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 48s 214ms/step - loss: 0.9012 - acc: 0.6982 - val_loss: 0.8117 - val_acc: 0.7194\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.8621 - acc: 0.7125 - val_loss: 0.8685 - val_acc: 0.6972\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 48s 214ms/step - loss: 0.8763 - acc: 0.7008 - val_loss: 0.8152 - val_acc: 0.7128\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.9024 - acc: 0.7018 - val_loss: 0.7728 - val_acc: 0.7256\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.8519 - acc: 0.7125 - val_loss: 0.8103 - val_acc: 0.7300\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.8641 - acc: 0.7128 - val_loss: 0.8367 - val_acc: 0.7067\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.8558 - acc: 0.7176 - val_loss: 0.7485 - val_acc: 0.7439\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 48s 216ms/step - loss: 0.8405 - acc: 0.7174 - val_loss: 0.8978 - val_acc: 0.7017\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.8529 - acc: 0.7168 - val_loss: 0.7640 - val_acc: 0.7350\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.8346 - acc: 0.7189 - val_loss: 0.8408 - val_acc: 0.6933\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.8550 - acc: 0.7133 - val_loss: 0.8136 - val_acc: 0.7150\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.8182 - acc: 0.7246 - val_loss: 0.7545 - val_acc: 0.7489\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.8268 - acc: 0.7257 - val_loss: 0.7764 - val_acc: 0.7344\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 48s 214ms/step - loss: 0.8282 - acc: 0.7224 - val_loss: 0.7453 - val_acc: 0.7389\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 48s 214ms/step - loss: 0.8061 - acc: 0.7371 - val_loss: 0.7939 - val_acc: 0.7411\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 48s 214ms/step - loss: 0.8092 - acc: 0.7322 - val_loss: 0.8867 - val_acc: 0.6967\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.7994 - acc: 0.7360 - val_loss: 0.7390 - val_acc: 0.7539\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.8029 - acc: 0.7324 - val_loss: 0.9146 - val_acc: 0.7039\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.7753 - acc: 0.7444 - val_loss: 0.7428 - val_acc: 0.7478\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 50s 220ms/step - loss: 0.7779 - acc: 0.7406 - val_loss: 0.7567 - val_acc: 0.7500\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 50s 222ms/step - loss: 0.7716 - acc: 0.7417 - val_loss: 0.8743 - val_acc: 0.7044\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.7633 - acc: 0.7440 - val_loss: 0.7645 - val_acc: 0.7378\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 50s 220ms/step - loss: 0.7607 - acc: 0.7419 - val_loss: 0.8557 - val_acc: 0.6994\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.7622 - acc: 0.7465 - val_loss: 0.8028 - val_acc: 0.7361\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.7444 - acc: 0.7525 - val_loss: 0.7145 - val_acc: 0.7550\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.7444 - acc: 0.7481 - val_loss: 0.6599 - val_acc: 0.7761\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.7445 - acc: 0.7540 - val_loss: 0.6960 - val_acc: 0.7661\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.7197 - acc: 0.7579 - val_loss: 0.7737 - val_acc: 0.7239\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.7151 - acc: 0.7610 - val_loss: 0.6754 - val_acc: 0.7783\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.7229 - acc: 0.7637 - val_loss: 0.7078 - val_acc: 0.7550\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.7043 - acc: 0.7642 - val_loss: 0.7891 - val_acc: 0.7294\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.7149 - acc: 0.7661 - val_loss: 0.7401 - val_acc: 0.7361\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.7121 - acc: 0.7667 - val_loss: 0.7682 - val_acc: 0.7461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d91809b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_3splits_mel.h5\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "# do crazy image generator stuff to randomize data\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 10\n",
    "                        )\n",
    "generator = gen.flow(X_train, y_train, batch_size = 32)\n",
    "# end of crazy image genertor stuff\n",
    "\n",
    "\n",
    "# adam = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model = build_model()\n",
    "model.compile(sgd, 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator, steps_per_epoch=len(X_train)/32, epochs=100, validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 54s 238ms/step - loss: 0.5521 - acc: 0.8147 - val_loss: 0.7215 - val_acc: 0.7583\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.5568 - acc: 0.8189 - val_loss: 0.6804 - val_acc: 0.7694\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.5533 - acc: 0.8149 - val_loss: 0.7528 - val_acc: 0.7506\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.5434 - acc: 0.8194 - val_loss: 0.6099 - val_acc: 0.8011\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.5235 - acc: 0.8233 - val_loss: 0.6872 - val_acc: 0.7661\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.5426 - acc: 0.8208 - val_loss: 0.6453 - val_acc: 0.7878\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 50s 222ms/step - loss: 0.5349 - acc: 0.8237 - val_loss: 0.6041 - val_acc: 0.8067\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 50s 220ms/step - loss: 0.5118 - acc: 0.8268 - val_loss: 0.6638 - val_acc: 0.7767\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.5410 - acc: 0.8231 - val_loss: 0.6863 - val_acc: 0.7667\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.5108 - acc: 0.8332 - val_loss: 0.5817 - val_acc: 0.8083\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.5315 - acc: 0.8257 - val_loss: 0.6639 - val_acc: 0.7856\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.5059 - acc: 0.8308 - val_loss: 0.6207 - val_acc: 0.8061\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.5178 - acc: 0.8271 - val_loss: 0.6520 - val_acc: 0.7850\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4819 - acc: 0.8400 - val_loss: 0.9173 - val_acc: 0.7311\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.4934 - acc: 0.8379 - val_loss: 0.6728 - val_acc: 0.7900\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4879 - acc: 0.8410 - val_loss: 0.6695 - val_acc: 0.7811\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4779 - acc: 0.8417 - val_loss: 0.7366 - val_acc: 0.7578\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4957 - acc: 0.8374 - val_loss: 0.7375 - val_acc: 0.7539\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4761 - acc: 0.8443 - val_loss: 0.6793 - val_acc: 0.7878\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4968 - acc: 0.8337 - val_loss: 0.6469 - val_acc: 0.7856\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.4743 - acc: 0.8357 - val_loss: 0.9549 - val_acc: 0.7261\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.4873 - acc: 0.8386 - val_loss: 0.7086 - val_acc: 0.7717\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4716 - acc: 0.8464 - val_loss: 0.6999 - val_acc: 0.7778\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4608 - acc: 0.8458 - val_loss: 0.6029 - val_acc: 0.7950\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4552 - acc: 0.8497 - val_loss: 0.8339 - val_acc: 0.7467\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4554 - acc: 0.8450 - val_loss: 0.6060 - val_acc: 0.7972\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4488 - acc: 0.8518 - val_loss: 0.7525 - val_acc: 0.7667\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4241 - acc: 0.8600 - val_loss: 0.6795 - val_acc: 0.7756\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4377 - acc: 0.8546 - val_loss: 0.7591 - val_acc: 0.7600\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4186 - acc: 0.8617 - val_loss: 0.7125 - val_acc: 0.7778\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4296 - acc: 0.8561 - val_loss: 0.7200 - val_acc: 0.7789\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4291 - acc: 0.8567 - val_loss: 0.6136 - val_acc: 0.8144\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.4116 - acc: 0.8607 - val_loss: 0.8203 - val_acc: 0.7544\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4342 - acc: 0.8567 - val_loss: 0.8540 - val_acc: 0.7578\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.4430 - acc: 0.8553 - val_loss: 0.8005 - val_acc: 0.7744\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3980 - acc: 0.8657 - val_loss: 0.6420 - val_acc: 0.7872\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4126 - acc: 0.8649 - val_loss: 0.7519 - val_acc: 0.7739\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.4072 - acc: 0.8643 - val_loss: 0.8941 - val_acc: 0.7472\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3938 - acc: 0.8689 - val_loss: 0.6376 - val_acc: 0.8150\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3899 - acc: 0.8660 - val_loss: 0.7962 - val_acc: 0.7783\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.4089 - acc: 0.8643 - val_loss: 0.7564 - val_acc: 0.7733\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3974 - acc: 0.8714 - val_loss: 0.5916 - val_acc: 0.8117\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3786 - acc: 0.8732 - val_loss: 0.6347 - val_acc: 0.8061\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 50s 220ms/step - loss: 0.3722 - acc: 0.8782 - val_loss: 0.6312 - val_acc: 0.8094\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.3788 - acc: 0.8706 - val_loss: 0.6120 - val_acc: 0.8239\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3737 - acc: 0.8733 - val_loss: 0.7424 - val_acc: 0.7850\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3616 - acc: 0.8831 - val_loss: 0.6222 - val_acc: 0.8061\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.3703 - acc: 0.8775 - val_loss: 0.6094 - val_acc: 0.8200\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3631 - acc: 0.8825 - val_loss: 0.6302 - val_acc: 0.8178\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3619 - acc: 0.8812 - val_loss: 0.8198 - val_acc: 0.7711\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3762 - acc: 0.8746 - val_loss: 0.9783 - val_acc: 0.7406\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.3739 - acc: 0.8733 - val_loss: 0.8779 - val_acc: 0.7667\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3735 - acc: 0.8789 - val_loss: 0.7205 - val_acc: 0.7956\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3517 - acc: 0.8810 - val_loss: 0.6148 - val_acc: 0.8139\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 50s 222ms/step - loss: 0.3478 - acc: 0.8815 - val_loss: 0.6318 - val_acc: 0.8128\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3755 - acc: 0.8760 - val_loss: 0.7801 - val_acc: 0.7817\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3431 - acc: 0.8857 - val_loss: 0.7908 - val_acc: 0.7667\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.3505 - acc: 0.8824 - val_loss: 0.6767 - val_acc: 0.8100\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.3359 - acc: 0.8887 - val_loss: 0.6521 - val_acc: 0.8206\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.3377 - acc: 0.8832 - val_loss: 0.8754 - val_acc: 0.7644\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.3430 - acc: 0.8815 - val_loss: 0.5626 - val_acc: 0.8350\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 49s 216ms/step - loss: 0.3322 - acc: 0.8887 - val_loss: 0.7725 - val_acc: 0.7833\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3558 - acc: 0.8815 - val_loss: 0.6879 - val_acc: 0.8011\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 51s 228ms/step - loss: 0.3323 - acc: 0.8881 - val_loss: 0.6929 - val_acc: 0.8178\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 50s 221ms/step - loss: 0.3293 - acc: 0.8919 - val_loss: 0.6388 - val_acc: 0.8111\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.3243 - acc: 0.8939 - val_loss: 0.6456 - val_acc: 0.8150\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.3084 - acc: 0.8971 - val_loss: 0.7431 - val_acc: 0.7972\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3165 - acc: 0.8939 - val_loss: 0.6644 - val_acc: 0.8039\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.3228 - acc: 0.8942 - val_loss: 0.6792 - val_acc: 0.8039\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3353 - acc: 0.8839 - val_loss: 0.6613 - val_acc: 0.8178\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3124 - acc: 0.8929 - val_loss: 0.6627 - val_acc: 0.8144\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3046 - acc: 0.9000 - val_loss: 0.6059 - val_acc: 0.8167\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.2891 - acc: 0.9039 - val_loss: 0.7664 - val_acc: 0.7883\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 50s 221ms/step - loss: 0.3071 - acc: 0.8969 - val_loss: 0.9875 - val_acc: 0.7450\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.3046 - acc: 0.8979 - val_loss: 0.7759 - val_acc: 0.7922\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.2931 - acc: 0.9019 - val_loss: 0.7620 - val_acc: 0.7889\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 49s 220ms/step - loss: 0.2967 - acc: 0.9021 - val_loss: 0.8275 - val_acc: 0.7700\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 49s 218ms/step - loss: 0.2983 - acc: 0.9018 - val_loss: 0.7327 - val_acc: 0.8044\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 49s 219ms/step - loss: 0.2756 - acc: 0.9075 - val_loss: 0.8162 - val_acc: 0.7750\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 50s 221ms/step - loss: 0.2828 - acc: 0.9053 - val_loss: 0.8326 - val_acc: 0.7650\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 50s 223ms/step - loss: 0.2881 - acc: 0.9038 - val_loss: 0.7505 - val_acc: 0.7939\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 66s 292ms/step - loss: 0.2919 - acc: 0.9047 - val_loss: 0.7306 - val_acc: 0.8017\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 64s 284ms/step - loss: 0.3001 - acc: 0.8972 - val_loss: 0.6346 - val_acc: 0.8228\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 51s 227ms/step - loss: 0.3018 - acc: 0.8990 - val_loss: 0.8665 - val_acc: 0.7844\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.2783 - acc: 0.9086 - val_loss: 0.6235 - val_acc: 0.8189\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 51s 225ms/step - loss: 0.2677 - acc: 0.9103 - val_loss: 0.7254 - val_acc: 0.8056\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 50s 223ms/step - loss: 0.2806 - acc: 0.9069 - val_loss: 0.6780 - val_acc: 0.8144\n",
      "Epoch 88/100\n",
      " 32/225 [===>..........................] - ETA: 28s - loss: 0.2700 - acc: 0.9121"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d5b63486cc26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m model.fit_generator(generator, steps_per_epoch=len(X_train)/32, epochs=100, validation_data=(X_train_validation, y_train_validation), \n\u001b[1;32m---> 26\u001b[1;33m          callbacks = [mcp])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_3splits_mel.h5\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "# do crazy image generator stuff to randomize data\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 10\n",
    "                        )\n",
    "generator = gen.flow(X_train, y_train, batch_size = 32)\n",
    "# end of crazy image genertor stuff\n",
    "\n",
    "\n",
    "# adam = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model = load_model(\"models/best_model_3splits_mel.h5\")\n",
    "model.compile(sgd, 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator, steps_per_epoch=len(X_train)/32, epochs=100, validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/trained_music_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step\n",
      "[3.419465198516846, 0.5800000071525574]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train_validation, y_train_validation, batch_size=32, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build second classifier, ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = Sequential()\n",
    "\n",
    "ann_model.add(Flatten())\n",
    "ann_model.add(Dense(512, activation = 'relu', input_shape = X_train.shape[1:]))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(256, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(128, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(64, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_2splits_50epochs_highLR\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "#adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "\n",
    "# Using custom adam is horrifically bad for ANN...\n",
    "ann_model.compile('adam', 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(X_train, y_train, batch_size=32, epochs=50 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "#### Default adam optimizer, 1 conv layer 128, and a FC layer of 128:\n",
    "    - No convergence\n",
    "#### Default adam optimizer, 2 conv layer 8 filters, and a FC layer of 16:\n",
    "    - No convergence\n",
    "#### Default adam optimizer, 2 conv layers and a FC layer of 64 neurons:\n",
    "    - No dropout or BN\n",
    "        - 99% train_acc, 60% val_acc, 10 epochs\n",
    "    - Using BatchNormalization\n",
    "        - BN at only FC layer overfit extremely fast and was stuck at about 53% val_acc\n",
    "        - BN at every layer still overfits extremely fast but gets to about 68% val_acc\n",
    "    - No BN, adding Dropout\n",
    "        - 0.75 dropout on just the dense layer before softmax -> 83% train_acc and 57% val_acc, in about 10 epochs\n",
    "        - 0.25 dropout on last layer, get about 97% train_acc with 54% val_acc -> in about 10 epochs\n",
    "        - 0.25 dropout on every layer, 100 epochs: 97% train_Acc with 60% val_acc\n",
    "        - 0.25 dropout on hidden layers, 0.5 dropout on output layer, 100 epochs: 80% train_acc and 58% val_acc\n",
    "        - 0.25 dropout on hidden layers, 0.35 dropout on output layer, 100 epochs: 97% train_acc and 58% val_acc\n",
    "#### Adam optimizer, LR = 0.0001, 2 conv layers and a FC layer of 64 neurons:\n",
    "    - No dropout or BN\n",
    "        - 99% train_acc, 62% val_acc, 20 epochs **not jumpy val_acc** -> starts going down after iteration 29\n",
    "        \n",
    "#### Adam optimizer, LR = 0.00001, 2 conv layers and a FC layer of 64 neurons:\n",
    "    - No dropout or BN\n",
    "        - Still gets up to 99% acc in about 25 epochs\n",
    "        \n",
    "#### SGD, sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True), 5-layer CNN, 64-256, FC 1024\n",
    "    - Dropout only on FC layer 0.5\n",
    "    - BatchNormalization after each activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 118, 168, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 118, 168, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 59, 84, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 53, 78, 128)       401536    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 53, 78, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 26, 39, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 20, 33, 256)       1605888   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 20, 33, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 10, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 40960)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                1310752   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,329,898\n",
      "Trainable params: 3,328,938\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "1800/1800 [==============================] - 5s 3ms/step\n",
      "[3 4 7 ... 0 7 7]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa59f36eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# build_confusion_matrix()\n",
    "# Builds the confusion matrix for either naive bayes' or logistic regression.\n",
    "# Our goal is to have a strong diagonal which corresponds to good correlation\n",
    "# between validation data classifications and our predictions.\n",
    "# true_classes are the classifications for the predictions and classes are the total range of classes\n",
    "def build_confusion_matrix(predictions, true_classes, classes, file_name):\n",
    "    confusion_matrix = np.zeros((len(classes), len(classes)), dtype='int')\n",
    "    len_pred = len(predictions)\n",
    "    print(true_classes)\n",
    "    # for every class prediction and true class value\n",
    "    for i in range(len_pred):\n",
    "        true_classification = np.where(true_classes[i]==1)\n",
    "#         print(true_classification)\n",
    "        # we hope that these two are equal for a strong diagonal correlation\n",
    "        confusion_matrix[predictions[i], true_classification] += 1\n",
    "\n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix, index= classes)\n",
    "    axis_label = [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]\n",
    "    figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.imshow(confusion_matrix_df.values, cmap='jet', interpolation='nearest')\n",
    "    plt.xticks(np.arange(10), axis_label, rotation='85')\n",
    "    plt.yticks(np.arange(10), axis_label)\n",
    "    plt.tick_params(axis='both', labelsize='10')\n",
    "    plt.xlabel(\"True classifications\")\n",
    "    plt.ylabel(\"Predicted classifications\")\n",
    "    plt.title(\"Confusion Matrix of Pred. Classes vs True Classes for Music Classification\")\n",
    "#     plt.tight_layout()\n",
    "    for (j, i), label in np.ndenumerate(confusion_matrix):\n",
    "        if label != 0:\n",
    "            plt.text(i,j,label,ha='center',va='center', size='10')\n",
    "    plt.show()\n",
    "\n",
    "    confusion_matrix_df.to_csv(file_name, sep=\",\", header=classes)\n",
    "\n",
    "model = load_model(\"models/best_model_3splits_mel.h5\")\n",
    "model.summary()\n",
    "\n",
    "predictions = model.predict_classes(X_train_validation, verbose=1)\n",
    "print(predictions)\n",
    "\n",
    "build_confusion_matrix(predictions, y_train_validation, np.arange(0,10), \"confusion_matrix_csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation neural network evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "num_of_folds = 10\n",
    "total_examples = len(X_train)\n",
    "size_of_one_fold = total_examples / 10\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_3splits_mel.h5\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "# adam = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "\n",
    "# training[:(i-1) * 900] + training[i * 900:]\n",
    "# validation[(i-1) * 900: i*900]\n",
    "\n",
    "for i in range(1, num_of_folds+1):\n",
    "#     print(X_train.shape)\n",
    "    print(\"\\nFold \" + str(i))\n",
    "    \n",
    "    # do cross validation stuff\n",
    "    \n",
    "    X_train_fold = np.concatenate((X_train[:((i-1) * 900), :, :, :], X_train[(i * 900):, :, :, :]))\n",
    "    y_train_fold = np.concatenate((y_train[:((i-1) * 900), :], y_train[(i * 900):, :]))\n",
    "    \n",
    "    X_train_validation_fold = X_train[((i-1) * 900) : (i * 900), :, :, :]\n",
    "    y_train_validation_fold = y_train[((i-1) * 900) : (i * 900), :]\n",
    "    print(\"Validation x train set:\" + str(X_train_validation_fold.shape))\n",
    "    print(\"X train set:\" + str(X_train_fold.shape))\n",
    "    print(\"Validation y train set:\" + str(y_train_validation_fold.shape))\n",
    "    print(\"Y train set:\" + str(y_train_fold.shape) + \"\\n\")\n",
    "    \n",
    "    # end cross-validation\n",
    "    \n",
    "    # get new model to train on\n",
    "    model = build_model()\n",
    "    \n",
    "    model.compile(sgd, 'categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train_fold, y_train_fold, batch_size=32, epochs=3 , validation_data=(X_train_validation_fold, \n",
    "            y_train_validation_fold), callbacks = [mcp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
