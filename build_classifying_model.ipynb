{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 'jupyter notebook' from Conda Terminal before beginning to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17812529919537992452\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3230007296\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13479776756620670816\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "Tensorflow:  1.11.0\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Testing to make sure TensorFlow GPU is working\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, shuffle data, normalize data, split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 124, 174, 3)\n",
      "(9000, 10)\n",
      "Validation x train set:(1800, 124, 174, 3)\n",
      "X train set:(7200, 124, 174, 3)\n",
      "Validation y train set:(1800, 10)\n",
      "Y train set:(7200, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load(\"X_train_3.dat\")\n",
    "y_train = np.load(\"y_train_3.dat\")\n",
    "\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "# reshape so in form for CNN-Keras\n",
    "#X_train = X_train.reshape(X_train.shape[0], 174, 124, 1)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# split data into validation set\n",
    "training_set_size = int(X_train.shape[0] * .80)\n",
    "X_train_validation = X_train[training_set_size:, :,:,:]\n",
    "y_train_validation = y_train[training_set_size:, :]\n",
    "y_train = y_train[:training_set_size,:]\n",
    "X_train = X_train[:training_set_size, :, :, :]\n",
    "print(\"Validation x train set:\" + str(X_train_validation.shape))\n",
    "print(\"X train set:\" + str(X_train.shape))\n",
    "print(\"Validation y train set:\" + str(y_train_validation.shape))\n",
    "print(\"Y train set:\" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 like network from Andrew Ng's course on Coursera\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (7,7), strides=(1,1), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(32, (7,7), strides=(1,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(64, (7, 7), strides=(1,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (7, 7), strides=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/200\n",
      "7200/7200 [==============================] - 26s 4ms/step - loss: 2.4823 - acc: 0.2112 - val_loss: 1.8573 - val_acc: 0.3739\n",
      "Epoch 2/200\n",
      "7200/7200 [==============================] - 24s 3ms/step - loss: 1.9771 - acc: 0.2887 - val_loss: 1.8455 - val_acc: 0.3400\n",
      "Epoch 3/200\n",
      "7200/7200 [==============================] - 24s 3ms/step - loss: 1.8120 - acc: 0.3421 - val_loss: 1.7084 - val_acc: 0.4056\n",
      "Epoch 4/200\n",
      "6752/7200 [===========================>..] - ETA: 1s - loss: 1.7581 - acc: 0.3556"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_3splits_200epochs_midLR\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "adam = Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(adam, 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=200 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/trained_music_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step\n",
      "[3.419465198516846, 0.5800000071525574]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train_validation, y_train_validation, batch_size=32, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run a NN without Convolutions (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10800 samples, validate on 2700 samples\n",
      "Epoch 1/50\n",
      "10800/10800 [==============================] - 9s 808us/step - loss: 2.2177 - acc: 0.2615 - val_loss: 1.8678 - val_acc: 0.3263\n",
      "Epoch 2/50\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 1.7888 - acc: 0.3276 - val_loss: 1.7145 - val_acc: 0.3489\n",
      "Epoch 3/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 1.7394 - acc: 0.3336 - val_loss: 1.7266 - val_acc: 0.3441\n",
      "Epoch 4/50\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 1.7063 - acc: 0.3481 - val_loss: 1.6665 - val_acc: 0.3526\n",
      "Epoch 5/50\n",
      "10800/10800 [==============================] - 8s 765us/step - loss: 1.6637 - acc: 0.3619 - val_loss: 1.6435 - val_acc: 0.3663\n",
      "Epoch 6/50\n",
      "10800/10800 [==============================] - 8s 769us/step - loss: 1.6464 - acc: 0.3694 - val_loss: 1.6415 - val_acc: 0.3593\n",
      "Epoch 7/50\n",
      "10800/10800 [==============================] - 8s 771us/step - loss: 1.6206 - acc: 0.3740 - val_loss: 1.6603 - val_acc: 0.3715\n",
      "Epoch 8/50\n",
      "10800/10800 [==============================] - 8s 778us/step - loss: 1.5958 - acc: 0.3906 - val_loss: 1.5828 - val_acc: 0.3881\n",
      "Epoch 9/50\n",
      "10800/10800 [==============================] - 8s 775us/step - loss: 1.5667 - acc: 0.3987 - val_loss: 1.5776 - val_acc: 0.3900\n",
      "Epoch 10/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 1.5742 - acc: 0.3990 - val_loss: 1.5909 - val_acc: 0.4037\n",
      "Epoch 11/50\n",
      "10800/10800 [==============================] - 8s 776us/step - loss: 1.5262 - acc: 0.4081 - val_loss: 1.5275 - val_acc: 0.4241\n",
      "Epoch 12/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 1.5417 - acc: 0.4040 - val_loss: 1.5034 - val_acc: 0.4185\n",
      "Epoch 13/50\n",
      "10800/10800 [==============================] - 8s 778us/step - loss: 1.5197 - acc: 0.4191 - val_loss: 1.5708 - val_acc: 0.4111\n",
      "Epoch 14/50\n",
      "10800/10800 [==============================] - 8s 772us/step - loss: 1.5006 - acc: 0.4252 - val_loss: 1.4838 - val_acc: 0.4319\n",
      "Epoch 15/50\n",
      "10800/10800 [==============================] - 8s 775us/step - loss: 1.4767 - acc: 0.4300 - val_loss: 1.5347 - val_acc: 0.4241\n",
      "Epoch 16/50\n",
      "10800/10800 [==============================] - 8s 771us/step - loss: 1.4803 - acc: 0.4309 - val_loss: 1.4866 - val_acc: 0.4470\n",
      "Epoch 17/50\n",
      "10800/10800 [==============================] - 8s 768us/step - loss: 1.4576 - acc: 0.4419 - val_loss: 1.5038 - val_acc: 0.4448\n",
      "Epoch 18/50\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 1.4293 - acc: 0.4482 - val_loss: 1.4375 - val_acc: 0.4600\n",
      "Epoch 19/50\n",
      "10800/10800 [==============================] - 8s 755us/step - loss: 1.4151 - acc: 0.4552 - val_loss: 1.5154 - val_acc: 0.4363\n",
      "Epoch 20/50\n",
      "10800/10800 [==============================] - 8s 755us/step - loss: 1.4022 - acc: 0.4640 - val_loss: 1.4537 - val_acc: 0.4415\n",
      "Epoch 21/50\n",
      "10800/10800 [==============================] - 8s 761us/step - loss: 1.3943 - acc: 0.4644 - val_loss: 1.4050 - val_acc: 0.4689\n",
      "Epoch 22/50\n",
      "10800/10800 [==============================] - 8s 772us/step - loss: 1.3951 - acc: 0.4641 - val_loss: 1.5439 - val_acc: 0.4341\n",
      "Epoch 23/50\n",
      "10800/10800 [==============================] - 8s 772us/step - loss: 1.3476 - acc: 0.4837 - val_loss: 1.5982 - val_acc: 0.4152\n",
      "Epoch 24/50\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 1.3514 - acc: 0.4789 - val_loss: 1.4116 - val_acc: 0.4585\n",
      "Epoch 25/50\n",
      "10800/10800 [==============================] - 8s 759us/step - loss: 1.3244 - acc: 0.4893 - val_loss: 1.5027 - val_acc: 0.4607\n",
      "Epoch 26/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 1.3025 - acc: 0.5040 - val_loss: 1.3344 - val_acc: 0.4893\n",
      "Epoch 27/50\n",
      "10800/10800 [==============================] - 8s 760us/step - loss: 1.2893 - acc: 0.5071 - val_loss: 1.3861 - val_acc: 0.4715\n",
      "Epoch 28/50\n",
      "10800/10800 [==============================] - 8s 757us/step - loss: 1.2593 - acc: 0.5185 - val_loss: 1.3984 - val_acc: 0.4811\n",
      "Epoch 29/50\n",
      "10800/10800 [==============================] - 8s 754us/step - loss: 1.2665 - acc: 0.5191 - val_loss: 1.3502 - val_acc: 0.4852\n",
      "Epoch 30/50\n",
      "10800/10800 [==============================] - 8s 765us/step - loss: 1.2563 - acc: 0.5178 - val_loss: 1.4195 - val_acc: 0.4630\n",
      "Epoch 31/50\n",
      "10800/10800 [==============================] - 8s 755us/step - loss: 1.2280 - acc: 0.5361 - val_loss: 1.3673 - val_acc: 0.4911\n",
      "Epoch 32/50\n",
      "10800/10800 [==============================] - 8s 756us/step - loss: 1.2175 - acc: 0.5371 - val_loss: 1.3826 - val_acc: 0.4911\n",
      "Epoch 33/50\n",
      "10800/10800 [==============================] - 8s 749us/step - loss: 1.2117 - acc: 0.5420 - val_loss: 1.3353 - val_acc: 0.5119\n",
      "Epoch 34/50\n",
      "10800/10800 [==============================] - 8s 749us/step - loss: 1.1874 - acc: 0.5514 - val_loss: 1.3617 - val_acc: 0.4948\n",
      "Epoch 35/50\n",
      "10800/10800 [==============================] - 8s 750us/step - loss: 1.1925 - acc: 0.5488 - val_loss: 1.3515 - val_acc: 0.5048\n",
      "Epoch 36/50\n",
      "10800/10800 [==============================] - 8s 767us/step - loss: 1.1704 - acc: 0.5559 - val_loss: 1.2659 - val_acc: 0.5463\n",
      "Epoch 37/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 1.1529 - acc: 0.5650 - val_loss: 1.3087 - val_acc: 0.5226\n",
      "Epoch 38/50\n",
      "10800/10800 [==============================] - 8s 760us/step - loss: 1.1509 - acc: 0.5594 - val_loss: 1.2222 - val_acc: 0.5585\n",
      "Epoch 39/50\n",
      "10800/10800 [==============================] - 9s 789us/step - loss: 1.1259 - acc: 0.5719 - val_loss: 1.3731 - val_acc: 0.4996\n",
      "Epoch 40/50\n",
      "10800/10800 [==============================] - 8s 764us/step - loss: 1.0743 - acc: 0.5921 - val_loss: 1.3668 - val_acc: 0.5056\n",
      "Epoch 41/50\n",
      "10800/10800 [==============================] - 8s 743us/step - loss: 1.0928 - acc: 0.5816 - val_loss: 1.3875 - val_acc: 0.5044\n",
      "Epoch 42/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 1.0786 - acc: 0.5876 - val_loss: 1.2451 - val_acc: 0.5433\n",
      "Epoch 43/50\n",
      "10800/10800 [==============================] - 8s 743us/step - loss: 1.0622 - acc: 0.5951 - val_loss: 1.2131 - val_acc: 0.5622\n",
      "Epoch 44/50\n",
      "10800/10800 [==============================] - 8s 742us/step - loss: 1.0557 - acc: 0.6019 - val_loss: 1.2264 - val_acc: 0.5689\n",
      "Epoch 45/50\n",
      "10800/10800 [==============================] - 8s 742us/step - loss: 1.0293 - acc: 0.6091 - val_loss: 1.3269 - val_acc: 0.5385\n",
      "Epoch 46/50\n",
      "10800/10800 [==============================] - 8s 743us/step - loss: 1.0347 - acc: 0.6129 - val_loss: 1.4309 - val_acc: 0.5059\n",
      "Epoch 47/50\n",
      "10800/10800 [==============================] - 8s 742us/step - loss: 1.0223 - acc: 0.6115 - val_loss: 1.2037 - val_acc: 0.5681\n",
      "Epoch 48/50\n",
      "10800/10800 [==============================] - 8s 747us/step - loss: 0.9970 - acc: 0.6207 - val_loss: 1.2387 - val_acc: 0.5570\n",
      "Epoch 49/50\n",
      "10800/10800 [==============================] - 8s 757us/step - loss: 0.9816 - acc: 0.6289 - val_loss: 1.2693 - val_acc: 0.5456\n",
      "Epoch 50/50\n",
      "10800/10800 [==============================] - 8s 751us/step - loss: 0.9771 - acc: 0.6302 - val_loss: 1.2517 - val_acc: 0.5530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22a44bf4e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model = Sequential()\n",
    "\n",
    "ann_model.add(Flatten())\n",
    "ann_model.add(Dense(512, activation = 'relu', input_shape = X_train.shape[1:]))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(256, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(128, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(64, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_2splits_50epochs_highLR\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "#adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "\n",
    "# Using custom adam is horrifically bad for ANN...\n",
    "ann_model.compile('adam', 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(X_train, y_train, batch_size=32, epochs=50 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10800 samples, validate on 2700 samples\n",
      "Epoch 1/50\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 0.6543 - acc: 0.7602 - val_loss: 1.6736 - val_acc: 0.5515\n",
      "Epoch 2/50\n",
      "10800/10800 [==============================] - 8s 771us/step - loss: 0.6608 - acc: 0.7577 - val_loss: 1.4058 - val_acc: 0.6122\n",
      "Epoch 3/50\n",
      "10800/10800 [==============================] - 8s 757us/step - loss: 0.6175 - acc: 0.7681 - val_loss: 1.3964 - val_acc: 0.6078\n",
      "Epoch 4/50\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 0.6041 - acc: 0.7754 - val_loss: 1.3546 - val_acc: 0.6093\n",
      "Epoch 5/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 0.5754 - acc: 0.7869 - val_loss: 1.6289 - val_acc: 0.5681\n",
      "Epoch 6/50\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 0.6426 - acc: 0.7673 - val_loss: 1.4995 - val_acc: 0.5974\n",
      "Epoch 7/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 0.5832 - acc: 0.7793 - val_loss: 1.2997 - val_acc: 0.6237\n",
      "Epoch 8/50\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 0.6545 - acc: 0.7558 - val_loss: 1.4058 - val_acc: 0.6089\n",
      "Epoch 9/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 0.5244 - acc: 0.8044 - val_loss: 1.4393 - val_acc: 0.5956\n",
      "Epoch 10/50\n",
      "10800/10800 [==============================] - 8s 770us/step - loss: 0.5832 - acc: 0.7881 - val_loss: 1.3453 - val_acc: 0.6041\n",
      "Epoch 11/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 0.5998 - acc: 0.7819 - val_loss: 1.3840 - val_acc: 0.6007\n",
      "Epoch 12/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 0.5549 - acc: 0.7955 - val_loss: 1.6084 - val_acc: 0.5570\n",
      "Epoch 13/50\n",
      "10800/10800 [==============================] - 8s 775us/step - loss: 0.5541 - acc: 0.7950 - val_loss: 1.4427 - val_acc: 0.5967\n",
      "Epoch 14/50\n",
      "10800/10800 [==============================] - 8s 772us/step - loss: 0.5815 - acc: 0.7881 - val_loss: 1.7903 - val_acc: 0.5030\n",
      "Epoch 15/50\n",
      "10800/10800 [==============================] - 8s 772us/step - loss: 0.6096 - acc: 0.7748 - val_loss: 1.4038 - val_acc: 0.6193\n",
      "Epoch 16/50\n",
      "10800/10800 [==============================] - 8s 766us/step - loss: 0.5553 - acc: 0.7911 - val_loss: 1.3447 - val_acc: 0.6096\n",
      "Epoch 17/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 0.5363 - acc: 0.8001 - val_loss: 1.3895 - val_acc: 0.6170\n",
      "Epoch 18/50\n",
      "10800/10800 [==============================] - 8s 764us/step - loss: 0.6234 - acc: 0.7753 - val_loss: 1.5391 - val_acc: 0.5593\n",
      "Epoch 19/50\n",
      "10800/10800 [==============================] - 8s 755us/step - loss: 0.5074 - acc: 0.8089 - val_loss: 1.5259 - val_acc: 0.5863\n",
      "Epoch 20/50\n",
      "10800/10800 [==============================] - 8s 761us/step - loss: 0.6320 - acc: 0.7712 - val_loss: 1.3976 - val_acc: 0.5996\n",
      "Epoch 21/50\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 0.5185 - acc: 0.8091 - val_loss: 1.6225 - val_acc: 0.5704\n",
      "Epoch 22/50\n",
      "10800/10800 [==============================] - 8s 784us/step - loss: 0.5465 - acc: 0.8003 - val_loss: 1.3964 - val_acc: 0.6048\n",
      "Epoch 23/50\n",
      "10800/10800 [==============================] - 8s 745us/step - loss: 0.4898 - acc: 0.8174 - val_loss: 1.3225 - val_acc: 0.6181\n",
      "Epoch 24/50\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 0.5383 - acc: 0.7981 - val_loss: 1.5127 - val_acc: 0.5907\n",
      "Epoch 25/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 0.5052 - acc: 0.8127 - val_loss: 1.4084 - val_acc: 0.6137\n",
      "Epoch 26/50\n",
      "10800/10800 [==============================] - 8s 782us/step - loss: 0.4818 - acc: 0.8237 - val_loss: 1.6939 - val_acc: 0.5604\n",
      "Epoch 27/50\n",
      "10800/10800 [==============================] - 9s 788us/step - loss: 0.5234 - acc: 0.8057 - val_loss: 1.5023 - val_acc: 0.6152\n",
      "Epoch 28/50\n",
      "10800/10800 [==============================] - 8s 783us/step - loss: 0.5267 - acc: 0.8021 - val_loss: 1.7949 - val_acc: 0.5270\n",
      "Epoch 29/50\n",
      "10800/10800 [==============================] - 8s 756us/step - loss: 0.5711 - acc: 0.7944 - val_loss: 1.4016 - val_acc: 0.6026\n",
      "Epoch 30/50\n",
      "10800/10800 [==============================] - 8s 753us/step - loss: 0.4379 - acc: 0.8381 - val_loss: 1.7432 - val_acc: 0.5889\n",
      "Epoch 31/50\n",
      "10800/10800 [==============================] - 8s 750us/step - loss: 0.4798 - acc: 0.8256 - val_loss: 1.5559 - val_acc: 0.6137\n",
      "Epoch 32/50\n",
      "10800/10800 [==============================] - 8s 748us/step - loss: 0.4793 - acc: 0.8198 - val_loss: 1.6232 - val_acc: 0.5874\n",
      "Epoch 33/50\n",
      "10800/10800 [==============================] - 8s 748us/step - loss: 0.4534 - acc: 0.8298 - val_loss: 1.6844 - val_acc: 0.5900\n",
      "Epoch 34/50\n",
      "10800/10800 [==============================] - 8s 748us/step - loss: 0.5145 - acc: 0.8081 - val_loss: 1.5628 - val_acc: 0.5933\n",
      "Epoch 35/50\n",
      "10800/10800 [==============================] - 8s 746us/step - loss: 0.4820 - acc: 0.8205 - val_loss: 1.5953 - val_acc: 0.6093\n",
      "Epoch 36/50\n",
      "10800/10800 [==============================] - 8s 748us/step - loss: 0.5205 - acc: 0.8101 - val_loss: 1.4555 - val_acc: 0.6159\n",
      "Epoch 37/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.5618 - acc: 0.7944 - val_loss: 1.4172 - val_acc: 0.6081\n",
      "Epoch 38/50\n",
      "10800/10800 [==============================] - 8s 745us/step - loss: 0.4995 - acc: 0.8171 - val_loss: 1.4094 - val_acc: 0.6241\n",
      "Epoch 39/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4289 - acc: 0.8402 - val_loss: 1.7433 - val_acc: 0.5493\n",
      "Epoch 40/50\n",
      "10800/10800 [==============================] - 8s 743us/step - loss: 0.4865 - acc: 0.8199 - val_loss: 1.5854 - val_acc: 0.5952\n",
      "Epoch 41/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.5279 - acc: 0.8087 - val_loss: 1.8476 - val_acc: 0.5493\n",
      "Epoch 42/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4112 - acc: 0.8472 - val_loss: 1.6780 - val_acc: 0.6052\n",
      "Epoch 43/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4440 - acc: 0.8383 - val_loss: 1.4224 - val_acc: 0.6244\n",
      "Epoch 44/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4879 - acc: 0.8221 - val_loss: 1.5003 - val_acc: 0.6270\n",
      "Epoch 45/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4654 - acc: 0.8259 - val_loss: 1.3584 - val_acc: 0.6404\n",
      "Epoch 46/50\n",
      "10800/10800 [==============================] - 8s 747us/step - loss: 0.5055 - acc: 0.8199 - val_loss: 1.4513 - val_acc: 0.6267\n",
      "Epoch 47/50\n",
      "10800/10800 [==============================] - 8s 747us/step - loss: 0.4350 - acc: 0.8394 - val_loss: 1.4915 - val_acc: 0.6111\n",
      "Epoch 48/50\n",
      "10800/10800 [==============================] - 8s 750us/step - loss: 0.4609 - acc: 0.8352 - val_loss: 1.3765 - val_acc: 0.6252\n",
      "Epoch 49/50\n",
      "10800/10800 [==============================] - 8s 749us/step - loss: 0.4984 - acc: 0.8215 - val_loss: 1.3839 - val_acc: 0.6307\n",
      "Epoch 50/50\n",
      "10800/10800 [==============================] - 8s 746us/step - loss: 0.4301 - acc: 0.8425 - val_loss: 1.7200 - val_acc: 0.5844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22a4512e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.fit(X_train, y_train, batch_size=32, epochs=50 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
