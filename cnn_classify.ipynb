{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 'jupyter notebook' from Conda Terminal before beginning to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4908570464288356736\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3805675520\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3574269181951922708\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "Tensorflow:  1.11.0\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Testing to make sure TensorFlow GPU is working\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, shuffle data, normalize data, split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 124, 174, 3)\n",
      "(9000, 10)\n",
      "Validation x train set:(1800, 124, 174, 3)\n",
      "X train set:(7200, 124, 174, 3)\n",
      "Validation y train set:(1800, 10)\n",
      "Y train set:(7200, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load(\"X_train_3.dat\")\n",
    "y_train = np.load(\"y_train_3.dat\")\n",
    "\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "# reshape so in form for CNN-Keras\n",
    "#X_train = X_train.reshape(X_train.shape[0], 174, 124, 1)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# split data into validation set\n",
    "training_set_size = int(X_train.shape[0] * .80)\n",
    "X_train_validation = X_train[training_set_size:, :,:,:]\n",
    "y_train_validation = y_train[training_set_size:, :]\n",
    "y_train = y_train[:training_set_size,:]\n",
    "X_train = X_train[:training_set_size, :, :, :]\n",
    "print(\"Validation x train set:\" + str(X_train_validation.shape))\n",
    "print(\"X train set:\" + str(X_train.shape))\n",
    "print(\"Validation y train set:\" + str(y_train_validation.shape))\n",
    "print(\"Y train set:\" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 like network from Andrew Ng's course on Coursera\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(64, (7,7), strides=(1,1), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(128, (11,11), strides=(1,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, (7, 7), strides=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(64, (7, 7), strides=(1,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 66s 9ms/step - loss: 2.0018 - acc: 0.3439 - val_loss: 1.4261 - val_acc: 0.4733\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 1.5063 - acc: 0.4851 - val_loss: 1.7759 - val_acc: 0.4006\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 63s 9ms/step - loss: 1.2626 - acc: 0.5640 - val_loss: 1.1314 - val_acc: 0.6028\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 63s 9ms/step - loss: 1.0504 - acc: 0.6394 - val_loss: 1.3352 - val_acc: 0.5500\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 63s 9ms/step - loss: 0.8297 - acc: 0.7208 - val_loss: 1.1830 - val_acc: 0.5956\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.6116 - acc: 0.8001 - val_loss: 1.1199 - val_acc: 0.6278\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.5869 - acc: 0.8053 - val_loss: 0.8952 - val_acc: 0.6983\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.3847 - acc: 0.8739 - val_loss: 0.9843 - val_acc: 0.6833\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.2577 - acc: 0.9200 - val_loss: 0.8760 - val_acc: 0.7028\n",
      "Epoch 10/100\n",
      "  32/7200 [..............................] - ETA: 1:03 - loss: 0.2566 - acc: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anthony/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.335030). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 63s 9ms/step - loss: 0.1910 - acc: 0.9410 - val_loss: 0.8310 - val_acc: 0.7317\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.1344 - acc: 0.9635 - val_loss: 0.8967 - val_acc: 0.7294\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.1004 - acc: 0.9726 - val_loss: 0.8594 - val_acc: 0.7522\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 63s 9ms/step - loss: 0.0820 - acc: 0.9801 - val_loss: 0.9819 - val_acc: 0.7167\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0683 - acc: 0.9815 - val_loss: 0.8502 - val_acc: 0.7472\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 63s 9ms/step - loss: 0.0620 - acc: 0.9850 - val_loss: 0.8754 - val_acc: 0.7478\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0600 - acc: 0.9843 - val_loss: 0.8799 - val_acc: 0.7439\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0508 - acc: 0.9885 - val_loss: 0.9109 - val_acc: 0.7439\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0443 - acc: 0.9882 - val_loss: 0.8980 - val_acc: 0.7494\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0412 - acc: 0.9894 - val_loss: 0.8792 - val_acc: 0.7528\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0341 - acc: 0.9914 - val_loss: 0.9193 - val_acc: 0.7539\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 63s 9ms/step - loss: 0.0333 - acc: 0.9917 - val_loss: 1.0027 - val_acc: 0.7444\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0347 - acc: 0.9907 - val_loss: 0.8825 - val_acc: 0.7683\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 63s 9ms/step - loss: 0.0275 - acc: 0.9939 - val_loss: 0.8886 - val_acc: 0.7556\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0234 - acc: 0.9944 - val_loss: 0.9131 - val_acc: 0.7528\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0260 - acc: 0.9929 - val_loss: 1.0099 - val_acc: 0.7444\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0218 - acc: 0.9939 - val_loss: 0.9288 - val_acc: 0.7622\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0196 - acc: 0.9957 - val_loss: 0.8924 - val_acc: 0.7656\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0240 - acc: 0.9926 - val_loss: 0.9199 - val_acc: 0.7706\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 63s 9ms/step - loss: 0.0245 - acc: 0.9933 - val_loss: 0.9067 - val_acc: 0.7633\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 62s 9ms/step - loss: 0.0197 - acc: 0.9957 - val_loss: 0.9030 - val_acc: 0.7717\n",
      "Epoch 31/100\n",
      "2112/7200 [=======>......................] - ETA: 41s - loss: 0.0167 - acc: 0.9972"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_3splits_200epochs_midLR\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "adam = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(adam, 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/trained_music_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step\n",
      "[3.419465198516846, 0.5800000071525574]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train_validation, y_train_validation, batch_size=32, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
