{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 'jupyter notebook' from Conda Terminal before beginning to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9763411444801929591\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3805675520\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14586692326263327933\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "Tensorflow:  1.11.0\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "# from keras.preprocessing import image\n",
    "# from keras.utils import layer_utils\n",
    "# from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# # Testing to make sure TensorFlow GPU is working\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, shuffle data, normalize data, split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 124, 174, 3)\n",
      "(9000, 10)\n",
      "Validation x train set:(1800, 124, 174, 3)\n",
      "X train set:(7200, 124, 174, 3)\n",
      "Validation y train set:(1800, 10)\n",
      "Y train set:(7200, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load(\"X_train_3.dat\")\n",
    "y_train = np.load(\"y_train_3.dat\")\n",
    "\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "# reshape so in form for CNN-Keras\n",
    "#X_train = X_train.reshape(X_train.shape[0], 174, 124, 1)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# split data into validation set\n",
    "training_set_size = int(X_train.shape[0] * .80)\n",
    "X_train_validation = X_train[training_set_size:, :,:,:]\n",
    "y_train_validation = y_train[training_set_size:, :]\n",
    "y_train = y_train[:training_set_size,:]\n",
    "X_train = X_train[:training_set_size, :, :, :]\n",
    "print(\"Validation x train set:\" + str(X_train_validation.shape))\n",
    "print(\"X train set:\" + str(X_train.shape))\n",
    "print(\"Validation y train set:\" + str(y_train_validation.shape))\n",
    "print(\"Y train set:\" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run a NN without Convolutions (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Flatten' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b8371d256464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mann_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mann_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mann_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#ann_model.add(Dropout(0.5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Flatten' is not defined"
     ]
    }
   ],
   "source": [
    "ann_model = Sequential()\n",
    "\n",
    "ann_model.add(Flatten())\n",
    "ann_model.add(Dense(512, activation = 'relu', input_shape = X_train.shape[1:]))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(256, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(128, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(64, activation = 'relu'))\n",
    "#ann_model.add(Dropout(0.5))\n",
    "\n",
    "ann_model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model_2splits_50epochs_highLR\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "#adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "\n",
    "# Using custom adam is horrifically bad for ANN...\n",
    "ann_model.compile('adam', 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(X_train, y_train, batch_size=32, epochs=50 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10800 samples, validate on 2700 samples\n",
      "Epoch 1/50\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 0.6543 - acc: 0.7602 - val_loss: 1.6736 - val_acc: 0.5515\n",
      "Epoch 2/50\n",
      "10800/10800 [==============================] - 8s 771us/step - loss: 0.6608 - acc: 0.7577 - val_loss: 1.4058 - val_acc: 0.6122\n",
      "Epoch 3/50\n",
      "10800/10800 [==============================] - 8s 757us/step - loss: 0.6175 - acc: 0.7681 - val_loss: 1.3964 - val_acc: 0.6078\n",
      "Epoch 4/50\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 0.6041 - acc: 0.7754 - val_loss: 1.3546 - val_acc: 0.6093\n",
      "Epoch 5/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 0.5754 - acc: 0.7869 - val_loss: 1.6289 - val_acc: 0.5681\n",
      "Epoch 6/50\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 0.6426 - acc: 0.7673 - val_loss: 1.4995 - val_acc: 0.5974\n",
      "Epoch 7/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 0.5832 - acc: 0.7793 - val_loss: 1.2997 - val_acc: 0.6237\n",
      "Epoch 8/50\n",
      "10800/10800 [==============================] - 8s 762us/step - loss: 0.6545 - acc: 0.7558 - val_loss: 1.4058 - val_acc: 0.6089\n",
      "Epoch 9/50\n",
      "10800/10800 [==============================] - 8s 763us/step - loss: 0.5244 - acc: 0.8044 - val_loss: 1.4393 - val_acc: 0.5956\n",
      "Epoch 10/50\n",
      "10800/10800 [==============================] - 8s 770us/step - loss: 0.5832 - acc: 0.7881 - val_loss: 1.3453 - val_acc: 0.6041\n",
      "Epoch 11/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 0.5998 - acc: 0.7819 - val_loss: 1.3840 - val_acc: 0.6007\n",
      "Epoch 12/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 0.5549 - acc: 0.7955 - val_loss: 1.6084 - val_acc: 0.5570\n",
      "Epoch 13/50\n",
      "10800/10800 [==============================] - 8s 775us/step - loss: 0.5541 - acc: 0.7950 - val_loss: 1.4427 - val_acc: 0.5967\n",
      "Epoch 14/50\n",
      "10800/10800 [==============================] - 8s 772us/step - loss: 0.5815 - acc: 0.7881 - val_loss: 1.7903 - val_acc: 0.5030\n",
      "Epoch 15/50\n",
      "10800/10800 [==============================] - 8s 772us/step - loss: 0.6096 - acc: 0.7748 - val_loss: 1.4038 - val_acc: 0.6193\n",
      "Epoch 16/50\n",
      "10800/10800 [==============================] - 8s 766us/step - loss: 0.5553 - acc: 0.7911 - val_loss: 1.3447 - val_acc: 0.6096\n",
      "Epoch 17/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 0.5363 - acc: 0.8001 - val_loss: 1.3895 - val_acc: 0.6170\n",
      "Epoch 18/50\n",
      "10800/10800 [==============================] - 8s 764us/step - loss: 0.6234 - acc: 0.7753 - val_loss: 1.5391 - val_acc: 0.5593\n",
      "Epoch 19/50\n",
      "10800/10800 [==============================] - 8s 755us/step - loss: 0.5074 - acc: 0.8089 - val_loss: 1.5259 - val_acc: 0.5863\n",
      "Epoch 20/50\n",
      "10800/10800 [==============================] - 8s 761us/step - loss: 0.6320 - acc: 0.7712 - val_loss: 1.3976 - val_acc: 0.5996\n",
      "Epoch 21/50\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 0.5185 - acc: 0.8091 - val_loss: 1.6225 - val_acc: 0.5704\n",
      "Epoch 22/50\n",
      "10800/10800 [==============================] - 8s 784us/step - loss: 0.5465 - acc: 0.8003 - val_loss: 1.3964 - val_acc: 0.6048\n",
      "Epoch 23/50\n",
      "10800/10800 [==============================] - 8s 745us/step - loss: 0.4898 - acc: 0.8174 - val_loss: 1.3225 - val_acc: 0.6181\n",
      "Epoch 24/50\n",
      "10800/10800 [==============================] - 8s 758us/step - loss: 0.5383 - acc: 0.7981 - val_loss: 1.5127 - val_acc: 0.5907\n",
      "Epoch 25/50\n",
      "10800/10800 [==============================] - 8s 774us/step - loss: 0.5052 - acc: 0.8127 - val_loss: 1.4084 - val_acc: 0.6137\n",
      "Epoch 26/50\n",
      "10800/10800 [==============================] - 8s 782us/step - loss: 0.4818 - acc: 0.8237 - val_loss: 1.6939 - val_acc: 0.5604\n",
      "Epoch 27/50\n",
      "10800/10800 [==============================] - 9s 788us/step - loss: 0.5234 - acc: 0.8057 - val_loss: 1.5023 - val_acc: 0.6152\n",
      "Epoch 28/50\n",
      "10800/10800 [==============================] - 8s 783us/step - loss: 0.5267 - acc: 0.8021 - val_loss: 1.7949 - val_acc: 0.5270\n",
      "Epoch 29/50\n",
      "10800/10800 [==============================] - 8s 756us/step - loss: 0.5711 - acc: 0.7944 - val_loss: 1.4016 - val_acc: 0.6026\n",
      "Epoch 30/50\n",
      "10800/10800 [==============================] - 8s 753us/step - loss: 0.4379 - acc: 0.8381 - val_loss: 1.7432 - val_acc: 0.5889\n",
      "Epoch 31/50\n",
      "10800/10800 [==============================] - 8s 750us/step - loss: 0.4798 - acc: 0.8256 - val_loss: 1.5559 - val_acc: 0.6137\n",
      "Epoch 32/50\n",
      "10800/10800 [==============================] - 8s 748us/step - loss: 0.4793 - acc: 0.8198 - val_loss: 1.6232 - val_acc: 0.5874\n",
      "Epoch 33/50\n",
      "10800/10800 [==============================] - 8s 748us/step - loss: 0.4534 - acc: 0.8298 - val_loss: 1.6844 - val_acc: 0.5900\n",
      "Epoch 34/50\n",
      "10800/10800 [==============================] - 8s 748us/step - loss: 0.5145 - acc: 0.8081 - val_loss: 1.5628 - val_acc: 0.5933\n",
      "Epoch 35/50\n",
      "10800/10800 [==============================] - 8s 746us/step - loss: 0.4820 - acc: 0.8205 - val_loss: 1.5953 - val_acc: 0.6093\n",
      "Epoch 36/50\n",
      "10800/10800 [==============================] - 8s 748us/step - loss: 0.5205 - acc: 0.8101 - val_loss: 1.4555 - val_acc: 0.6159\n",
      "Epoch 37/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.5618 - acc: 0.7944 - val_loss: 1.4172 - val_acc: 0.6081\n",
      "Epoch 38/50\n",
      "10800/10800 [==============================] - 8s 745us/step - loss: 0.4995 - acc: 0.8171 - val_loss: 1.4094 - val_acc: 0.6241\n",
      "Epoch 39/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4289 - acc: 0.8402 - val_loss: 1.7433 - val_acc: 0.5493\n",
      "Epoch 40/50\n",
      "10800/10800 [==============================] - 8s 743us/step - loss: 0.4865 - acc: 0.8199 - val_loss: 1.5854 - val_acc: 0.5952\n",
      "Epoch 41/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.5279 - acc: 0.8087 - val_loss: 1.8476 - val_acc: 0.5493\n",
      "Epoch 42/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4112 - acc: 0.8472 - val_loss: 1.6780 - val_acc: 0.6052\n",
      "Epoch 43/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4440 - acc: 0.8383 - val_loss: 1.4224 - val_acc: 0.6244\n",
      "Epoch 44/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4879 - acc: 0.8221 - val_loss: 1.5003 - val_acc: 0.6270\n",
      "Epoch 45/50\n",
      "10800/10800 [==============================] - 8s 744us/step - loss: 0.4654 - acc: 0.8259 - val_loss: 1.3584 - val_acc: 0.6404\n",
      "Epoch 46/50\n",
      "10800/10800 [==============================] - 8s 747us/step - loss: 0.5055 - acc: 0.8199 - val_loss: 1.4513 - val_acc: 0.6267\n",
      "Epoch 47/50\n",
      "10800/10800 [==============================] - 8s 747us/step - loss: 0.4350 - acc: 0.8394 - val_loss: 1.4915 - val_acc: 0.6111\n",
      "Epoch 48/50\n",
      "10800/10800 [==============================] - 8s 750us/step - loss: 0.4609 - acc: 0.8352 - val_loss: 1.3765 - val_acc: 0.6252\n",
      "Epoch 49/50\n",
      "10800/10800 [==============================] - 8s 749us/step - loss: 0.4984 - acc: 0.8215 - val_loss: 1.3839 - val_acc: 0.6307\n",
      "Epoch 50/50\n",
      "10800/10800 [==============================] - 8s 746us/step - loss: 0.4301 - acc: 0.8425 - val_loss: 1.7200 - val_acc: 0.5844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22a4512e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model.fit(X_train, y_train, batch_size=32, epochs=50 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
