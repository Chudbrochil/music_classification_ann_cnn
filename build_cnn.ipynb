{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 'jupyter notebook' from Conda Terminal before beginning to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1646846974717347302\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3649437696\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7751581222681017358\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "Tensorflow:  1.11.0\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Testing to make sure TensorFlow GPU is working\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data, shuffle data, normalize data, split data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 124, 174, 3)\n",
      "(9000, 10)\n",
      "Validation x train set:(1800, 124, 174, 3)\n",
      "X train set:(7200, 124, 174, 3)\n",
      "Validation y train set:(1800, 10)\n",
      "Y train set:(7200, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the data\n",
    "X_train = np.load(\"X_train_3.dat\")\n",
    "y_train = np.load(\"y_train_3.dat\")\n",
    "\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "# reshape so in form for CNN-Keras\n",
    "#X_train = X_train.reshape(X_train.shape[0], 174, 124, 1)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# split data into validation set\n",
    "training_set_size = int(X_train.shape[0] * .80)\n",
    "X_train_validation = X_train[training_set_size:, :,:,:]\n",
    "y_train_validation = y_train[training_set_size:, :]\n",
    "y_train = y_train[:training_set_size,:]\n",
    "X_train = X_train[:training_set_size, :, :, :]\n",
    "print(\"Validation x train set:\" + str(X_train_validation.shape))\n",
    "print(\"X train set:\" + str(X_train.shape))\n",
    "print(\"Validation y train set:\" + str(y_train_validation.shape))\n",
    "print(\"Y train set:\" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 like network from Andrew Ng's course on Coursera\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(64, (7,7), strides=(1,1), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, (11,11), strides=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(128, (11, 11), strides=(1,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(256, (11, 11), strides=(1,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/200\n",
      "7200/7200 [==============================] - 72s 10ms/step - loss: 1.9674 - acc: 0.3543 - val_loss: 2.9018 - val_acc: 0.2189\n",
      "Epoch 2/200\n",
      "7200/7200 [==============================] - 72s 10ms/step - loss: 1.5448 - acc: 0.4722 - val_loss: 1.5530 - val_acc: 0.4439\n",
      "Epoch 3/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 1.2682 - acc: 0.5629 - val_loss: 1.9701 - val_acc: 0.3561\n",
      "Epoch 4/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 1.0859 - acc: 0.6215 - val_loss: 1.2020 - val_acc: 0.6000\n",
      "Epoch 5/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.9114 - acc: 0.6939 - val_loss: 2.0327 - val_acc: 0.4139\n",
      "Epoch 6/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.7885 - acc: 0.7300 - val_loss: 1.2204 - val_acc: 0.5833\n",
      "Epoch 7/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.5969 - acc: 0.8024 - val_loss: 1.0107 - val_acc: 0.6689\n",
      "Epoch 8/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.4245 - acc: 0.8638 - val_loss: 0.8954 - val_acc: 0.7017\n",
      "Epoch 9/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.3081 - acc: 0.9067 - val_loss: 0.9524 - val_acc: 0.6756\n",
      "Epoch 10/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.2119 - acc: 0.9339 - val_loss: 0.7869 - val_acc: 0.7500\n",
      "Epoch 11/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.1587 - acc: 0.9553 - val_loss: 0.8038 - val_acc: 0.7511\n",
      "Epoch 12/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.1239 - acc: 0.9653 - val_loss: 0.8842 - val_acc: 0.7294\n",
      "Epoch 13/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.1134 - acc: 0.9676 - val_loss: 0.8280 - val_acc: 0.7572\n",
      "Epoch 14/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0824 - acc: 0.9782 - val_loss: 0.8752 - val_acc: 0.7389\n",
      "Epoch 15/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0955 - acc: 0.9717 - val_loss: 0.8416 - val_acc: 0.7683\n",
      "Epoch 16/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.0625 - acc: 0.9847 - val_loss: 0.8126 - val_acc: 0.7600\n",
      "Epoch 17/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0469 - acc: 0.9883 - val_loss: 0.8365 - val_acc: 0.7711\n",
      "Epoch 18/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0377 - acc: 0.9921 - val_loss: 0.7995 - val_acc: 0.7822\n",
      "Epoch 19/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0364 - acc: 0.9919 - val_loss: 0.8119 - val_acc: 0.7828\n",
      "Epoch 20/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0356 - acc: 0.9911 - val_loss: 0.8491 - val_acc: 0.7822\n",
      "Epoch 21/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0357 - acc: 0.9908 - val_loss: 0.9053 - val_acc: 0.7639\n",
      "Epoch 22/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0411 - acc: 0.9883 - val_loss: 0.8375 - val_acc: 0.7806\n",
      "Epoch 23/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0318 - acc: 0.9921 - val_loss: 0.8259 - val_acc: 0.7833\n",
      "Epoch 24/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0300 - acc: 0.9918 - val_loss: 0.9252 - val_acc: 0.7644\n",
      "Epoch 25/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0242 - acc: 0.9946 - val_loss: 0.8942 - val_acc: 0.7694\n",
      "Epoch 26/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0254 - acc: 0.9933 - val_loss: 0.8891 - val_acc: 0.7750\n",
      "Epoch 27/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0206 - acc: 0.9951 - val_loss: 0.8782 - val_acc: 0.7711\n",
      "Epoch 28/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0195 - acc: 0.9957 - val_loss: 0.9166 - val_acc: 0.7761\n",
      "Epoch 29/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0174 - acc: 0.9965 - val_loss: 0.8952 - val_acc: 0.7744\n",
      "Epoch 30/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0161 - acc: 0.9961 - val_loss: 0.9660 - val_acc: 0.7667\n",
      "Epoch 31/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0188 - acc: 0.9951 - val_loss: 0.9055 - val_acc: 0.7739\n",
      "Epoch 32/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0172 - acc: 0.9965 - val_loss: 0.9607 - val_acc: 0.7767\n",
      "Epoch 33/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0158 - acc: 0.9960 - val_loss: 0.9787 - val_acc: 0.7689\n",
      "Epoch 34/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0146 - acc: 0.9965 - val_loss: 0.9376 - val_acc: 0.7800\n",
      "Epoch 35/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0166 - acc: 0.9962 - val_loss: 0.9155 - val_acc: 0.7783\n",
      "Epoch 36/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0120 - acc: 0.9979 - val_loss: 0.9406 - val_acc: 0.7761\n",
      "Epoch 37/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0137 - acc: 0.9964 - val_loss: 0.9793 - val_acc: 0.7772\n",
      "Epoch 38/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0119 - acc: 0.9971 - val_loss: 0.9310 - val_acc: 0.7811\n",
      "Epoch 39/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.9029 - val_acc: 0.7789\n",
      "Epoch 40/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0142 - acc: 0.9964 - val_loss: 0.9709 - val_acc: 0.7694\n",
      "Epoch 41/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0120 - acc: 0.9962 - val_loss: 0.9092 - val_acc: 0.7806\n",
      "Epoch 42/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0135 - acc: 0.9968 - val_loss: 0.9559 - val_acc: 0.7744\n",
      "Epoch 43/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0097 - acc: 0.9979 - val_loss: 0.9513 - val_acc: 0.7783\n",
      "Epoch 44/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0131 - acc: 0.9965 - val_loss: 0.9382 - val_acc: 0.7794\n",
      "Epoch 45/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.9526 - val_acc: 0.7806\n",
      "Epoch 46/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0098 - acc: 0.9976 - val_loss: 0.9964 - val_acc: 0.7761\n",
      "Epoch 47/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.9667 - val_acc: 0.7806\n",
      "Epoch 48/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.9894 - val_acc: 0.7750\n",
      "Epoch 49/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0090 - acc: 0.9981 - val_loss: 0.9389 - val_acc: 0.7828\n",
      "Epoch 50/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.9140 - val_acc: 0.7861\n",
      "Epoch 51/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 1.0138 - val_acc: 0.7822\n",
      "Epoch 52/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.9321 - val_acc: 0.7822\n",
      "Epoch 53/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 1.0265 - val_acc: 0.7678\n",
      "Epoch 54/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0060 - acc: 0.9989 - val_loss: 0.9634 - val_acc: 0.7789\n",
      "Epoch 55/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0069 - acc: 0.9985 - val_loss: 0.9734 - val_acc: 0.7922\n",
      "Epoch 56/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.9508 - val_acc: 0.7822\n",
      "Epoch 57/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 1.0319 - val_acc: 0.7672\n",
      "Epoch 58/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.9929 - val_acc: 0.7822\n",
      "Epoch 59/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 1.0007 - val_acc: 0.7772\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 1.0057 - val_acc: 0.7761\n",
      "Epoch 61/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0076 - acc: 0.9986 - val_loss: 1.0067 - val_acc: 0.7767\n",
      "Epoch 62/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 1.0323 - val_acc: 0.7817\n",
      "Epoch 63/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.9947 - val_acc: 0.7883\n",
      "Epoch 64/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0055 - acc: 0.9989 - val_loss: 1.0248 - val_acc: 0.7767\n",
      "Epoch 65/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.9848 - val_acc: 0.7783\n",
      "Epoch 66/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.9868 - val_acc: 0.7828\n",
      "Epoch 67/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.9877 - val_acc: 0.7900\n",
      "Epoch 68/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.9839 - val_acc: 0.7844\n",
      "Epoch 69/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.9819 - val_acc: 0.7817\n",
      "Epoch 70/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0061 - acc: 0.9988 - val_loss: 1.0250 - val_acc: 0.7867\n",
      "Epoch 71/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.9941 - val_acc: 0.7933\n",
      "Epoch 72/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.9977 - val_acc: 0.7844\n",
      "Epoch 73/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 1.0482 - val_acc: 0.7828\n",
      "Epoch 74/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 1.0485 - val_acc: 0.7850\n",
      "Epoch 75/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 1.0007 - val_acc: 0.7906\n",
      "Epoch 76/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 1.0066 - val_acc: 0.7933\n",
      "Epoch 77/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 1.0142 - val_acc: 0.7911\n",
      "Epoch 78/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.9746 - val_acc: 0.7867\n",
      "Epoch 79/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 1.0223 - val_acc: 0.7833\n",
      "Epoch 80/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 1.0324 - val_acc: 0.7900\n",
      "Epoch 81/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 1.0346 - val_acc: 0.7800\n",
      "Epoch 82/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0057 - acc: 0.9988 - val_loss: 1.0015 - val_acc: 0.7856\n",
      "Epoch 83/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0050 - acc: 0.9993 - val_loss: 1.0397 - val_acc: 0.7833\n",
      "Epoch 84/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 1.0346 - val_acc: 0.7828\n",
      "Epoch 85/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 1.0314 - val_acc: 0.7867\n",
      "Epoch 86/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 1.0660 - val_acc: 0.7833\n",
      "Epoch 87/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 1.0159 - val_acc: 0.7917\n",
      "Epoch 88/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.9976 - val_acc: 0.7889\n",
      "Epoch 89/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.9978 - val_acc: 0.7900\n",
      "Epoch 90/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 1.0092 - val_acc: 0.7917\n",
      "Epoch 91/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 0.9992 - val_acc: 0.7867\n",
      "Epoch 92/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0057 - acc: 0.9986 - val_loss: 1.0541 - val_acc: 0.7817\n",
      "Epoch 93/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 1.1140 - val_acc: 0.7733\n",
      "Epoch 94/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 1.0022 - val_acc: 0.7900\n",
      "Epoch 95/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 1.0000 - val_acc: 0.7900\n",
      "Epoch 96/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0033 - acc: 0.9988 - val_loss: 1.0398 - val_acc: 0.7817\n",
      "Epoch 97/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 1.0142 - val_acc: 0.7867\n",
      "Epoch 98/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 1.0207 - val_acc: 0.7883\n",
      "Epoch 99/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 1.0289 - val_acc: 0.7833\n",
      "Epoch 100/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0041 - acc: 0.9986 - val_loss: 1.0139 - val_acc: 0.7911\n",
      "Epoch 101/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 1.0341 - val_acc: 0.7900\n",
      "Epoch 102/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0040 - acc: 0.9985 - val_loss: 1.0041 - val_acc: 0.7906\n",
      "Epoch 103/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 1.0174 - val_acc: 0.7867\n",
      "Epoch 104/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 1.0276 - val_acc: 0.7950\n",
      "Epoch 105/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 1.0200 - val_acc: 0.7906\n",
      "Epoch 106/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0036 - acc: 0.9993 - val_loss: 1.0101 - val_acc: 0.7928\n",
      "Epoch 107/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 1.0227 - val_acc: 0.7839\n",
      "Epoch 108/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 1.0553 - val_acc: 0.7917\n",
      "Epoch 109/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 1.0567 - val_acc: 0.7889\n",
      "Epoch 110/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 1.0564 - val_acc: 0.7911\n",
      "Epoch 111/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 1.0416 - val_acc: 0.7844\n",
      "Epoch 112/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 1.0610 - val_acc: 0.7894\n",
      "Epoch 113/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 1.0605 - val_acc: 0.7822\n",
      "Epoch 114/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 1.0278 - val_acc: 0.7928\n",
      "Epoch 115/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 1.0303 - val_acc: 0.7917\n",
      "Epoch 116/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 1.0271 - val_acc: 0.7928\n",
      "Epoch 117/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 1.0291 - val_acc: 0.7917\n",
      "Epoch 118/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 1.0384 - val_acc: 0.7872\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 1.0289 - val_acc: 0.7900\n",
      "Epoch 120/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 1.0394 - val_acc: 0.7850\n",
      "Epoch 121/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 1.0438 - val_acc: 0.7861\n",
      "Epoch 122/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 1.0430 - val_acc: 0.7861\n",
      "Epoch 123/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 1.0306 - val_acc: 0.7839\n",
      "Epoch 124/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 1.0300 - val_acc: 0.7861\n",
      "Epoch 125/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0018 - acc: 0.9999 - val_loss: 1.0280 - val_acc: 0.7906\n",
      "Epoch 126/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 1.0435 - val_acc: 0.7861\n",
      "Epoch 127/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0025 - acc: 0.9989 - val_loss: 1.0420 - val_acc: 0.7811\n",
      "Epoch 128/200\n",
      "7200/7200 [==============================] - 73s 10ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 1.0274 - val_acc: 0.7867\n",
      "Epoch 129/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 1.0410 - val_acc: 0.7833\n",
      "Epoch 130/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0032 - acc: 0.9986 - val_loss: 1.0344 - val_acc: 0.7906\n",
      "Epoch 131/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 1.0354 - val_acc: 0.7894\n",
      "Epoch 132/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 1.0170 - val_acc: 0.7806\n",
      "Epoch 133/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 1.0190 - val_acc: 0.7911\n",
      "Epoch 134/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 1.0383 - val_acc: 0.7911\n",
      "Epoch 135/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 1.0377 - val_acc: 0.7883\n",
      "Epoch 136/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 1.0311 - val_acc: 0.7911\n",
      "Epoch 137/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 1.0360 - val_acc: 0.7928\n",
      "Epoch 138/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 1.0601 - val_acc: 0.7889\n",
      "Epoch 139/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 1.0468 - val_acc: 0.7883\n",
      "Epoch 140/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 1.0668 - val_acc: 0.7828\n",
      "Epoch 141/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 1.0653 - val_acc: 0.7844\n",
      "Epoch 142/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0010 - acc: 0.9999 - val_loss: 1.0458 - val_acc: 0.7922\n",
      "Epoch 143/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0029 - acc: 0.9989 - val_loss: 1.0638 - val_acc: 0.7889\n",
      "Epoch 144/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 1.0526 - val_acc: 0.7800\n",
      "Epoch 145/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0038 - acc: 0.9985 - val_loss: 1.0497 - val_acc: 0.7906\n",
      "Epoch 146/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 1.0554 - val_acc: 0.7867\n",
      "Epoch 147/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 1.0538 - val_acc: 0.7889\n",
      "Epoch 148/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0025 - acc: 0.9990 - val_loss: 1.0484 - val_acc: 0.7878\n",
      "Epoch 149/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 1.0559 - val_acc: 0.7906\n",
      "Epoch 150/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 1.0475 - val_acc: 0.7883\n",
      "Epoch 151/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0020 - acc: 0.9994 - val_loss: 1.0422 - val_acc: 0.7939\n",
      "Epoch 152/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.0444 - val_acc: 0.7956\n",
      "Epoch 153/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 1.0576 - val_acc: 0.7900\n",
      "Epoch 154/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 1.0598 - val_acc: 0.7944\n",
      "Epoch 155/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 1.0588 - val_acc: 0.7961\n",
      "Epoch 156/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 1.0661 - val_acc: 0.7922\n",
      "Epoch 157/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0033 - acc: 0.9986 - val_loss: 1.0638 - val_acc: 0.7839\n",
      "Epoch 158/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0030 - acc: 0.9989 - val_loss: 1.0342 - val_acc: 0.7944\n",
      "Epoch 159/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0037 - acc: 0.9993 - val_loss: 1.0421 - val_acc: 0.7956\n",
      "Epoch 160/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 1.0397 - val_acc: 0.7944\n",
      "Epoch 161/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 1.0556 - val_acc: 0.7961\n",
      "Epoch 162/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0025 - acc: 0.9990 - val_loss: 1.0540 - val_acc: 0.7839\n",
      "Epoch 163/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 1.0441 - val_acc: 0.7917\n",
      "Epoch 164/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0020 - acc: 0.9992 - val_loss: 1.0602 - val_acc: 0.7928\n",
      "Epoch 165/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0023 - acc: 0.9992 - val_loss: 1.0823 - val_acc: 0.7917\n",
      "Epoch 166/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 1.0468 - val_acc: 0.7961\n",
      "Epoch 167/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0024 - acc: 0.9990 - val_loss: 1.0352 - val_acc: 0.7928\n",
      "Epoch 168/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0015 - acc: 0.9993 - val_loss: 1.0679 - val_acc: 0.7950\n",
      "Epoch 169/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 1.0455 - val_acc: 0.7911\n",
      "Epoch 170/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 1.0644 - val_acc: 0.7872\n",
      "Epoch 171/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0024 - acc: 0.9990 - val_loss: 1.0470 - val_acc: 0.7922\n",
      "Epoch 172/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 1.0487 - val_acc: 0.7939\n",
      "Epoch 173/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 1.0649 - val_acc: 0.7922\n",
      "Epoch 174/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0037 - acc: 0.9986 - val_loss: 1.0657 - val_acc: 0.7872\n",
      "Epoch 175/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 1.0591 - val_acc: 0.7889\n",
      "Epoch 176/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 1.0639 - val_acc: 0.7900\n",
      "Epoch 177/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 1.0634 - val_acc: 0.7883\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 1.0668 - val_acc: 0.7900\n",
      "Epoch 179/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 1.0569 - val_acc: 0.7939\n",
      "Epoch 180/200\n",
      "7200/7200 [==============================] - 70s 10ms/step - loss: 0.0015 - acc: 0.9993 - val_loss: 1.0559 - val_acc: 0.7956\n",
      "Epoch 181/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 1.0590 - val_acc: 0.7911\n",
      "Epoch 182/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0028 - acc: 0.9989 - val_loss: 1.0394 - val_acc: 0.7906\n",
      "Epoch 183/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 1.0558 - val_acc: 0.7911\n",
      "Epoch 184/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 1.0745 - val_acc: 0.7856\n",
      "Epoch 185/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 1.0482 - val_acc: 0.7944\n",
      "Epoch 186/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 1.0477 - val_acc: 0.7922\n",
      "Epoch 187/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0030 - acc: 0.9989 - val_loss: 1.0752 - val_acc: 0.7889\n",
      "Epoch 188/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0031 - acc: 0.9988 - val_loss: 1.0552 - val_acc: 0.7889\n",
      "Epoch 189/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 9.5057e-04 - acc: 0.9997 - val_loss: 1.0526 - val_acc: 0.7939\n",
      "Epoch 190/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 1.0599 - val_acc: 0.7861\n",
      "Epoch 191/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 1.0755 - val_acc: 0.7922\n",
      "Epoch 192/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 1.0705 - val_acc: 0.7933\n",
      "Epoch 193/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0016 - acc: 0.9994 - val_loss: 1.0965 - val_acc: 0.7850\n",
      "Epoch 194/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 1.0831 - val_acc: 0.7906\n",
      "Epoch 195/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.0637 - val_acc: 0.7917\n",
      "Epoch 196/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.0678 - val_acc: 0.7933\n",
      "Epoch 197/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 1.0782 - val_acc: 0.7883\n",
      "Epoch 198/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 1.0635 - val_acc: 0.7883\n",
      "Epoch 199/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0013 - acc: 0.9994 - val_loss: 1.0636 - val_acc: 0.7961\n",
      "Epoch 200/200\n",
      "7200/7200 [==============================] - 69s 10ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 1.1353 - val_acc: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa487497b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mcp = ModelCheckpoint(\"models/best_model\", monitor='val_acc', verbose=0, \n",
    "                      save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "adam = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(adam, 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=200 , validation_data=(X_train_validation, y_train_validation), \n",
    "         callbacks = [mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/trained_music_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step\n",
      "[3.419465198516846, 0.5800000071525574]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train_validation, y_train_validation, batch_size=32, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
